# ğŸ§  HÆ¯á»šNG DáºªN CHI TIáº¾T: CÃCH MÃ” HÃŒNH PHOBERT PHÃ‚N TÃCH Cáº¢M XÃšC

---

## ğŸ“– Má»¤C Lá»¤C

1. [Giá»›i thiá»‡u tá»•ng quan](#1-giá»›i-thiá»‡u-tá»•ng-quan)
2. [BÆ°á»›c 1: Tiá»n xá»­ lÃ½ vÄƒn báº£n](#2-bÆ°á»›c-1-tiá»n-xá»­-lÃ½-vÄƒn-báº£n)
3. [BÆ°á»›c 2: Tokenization](#3-bÆ°á»›c-2-tokenization)
4. [BÆ°á»›c 3: Embedding](#4-bÆ°á»›c-3-embedding)
5. [BÆ°á»›c 4: Transformer Layers](#5-bÆ°á»›c-4-transformer-layers)
6. [BÆ°á»›c 5: Classification](#6-bÆ°á»›c-5-classification)
7. [BÆ°á»›c 6: Softmax vÃ  Káº¿t quáº£](#7-bÆ°á»›c-6-softmax-vÃ -káº¿t-quáº£)
8. [VÃ­ dá»¥ thá»±c táº¿ tá»« A-Z](#8-vÃ­-dá»¥-thá»±c-táº¿-tá»«-a-z)

---

## 1. GIá»šI THIá»†U Tá»”NG QUAN

### 1.1 PhoBERT lÃ  gÃ¬?

**PhoBERT** = **Pho**netic **B**idirectional **E**ncoder **R**epresentations from **T**ransformers

ÄÃ¢y lÃ  mÃ´ hÃ¬nh AI Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi **VinAI Research** (Viá»‡t Nam) Ä‘á»ƒ hiá»ƒu ngÃ´n ngá»¯ tiáº¿ng Viá»‡t. MÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn **20GB dá»¯ liá»‡u tiáº¿ng Viá»‡t** tá»« bÃ¡o chÃ­ vÃ  Wikipedia.

### 1.2 MÃ´ hÃ¬nh phÃ¢n loáº¡i cáº£m xÃºc

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Há»† THá»NG Cá»¦A Báº N                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  INPUT:  "Sáº£n pháº©m nÃ y ráº¥t tuyá»‡t vá»i!"                  â”‚
â”‚                         â†“                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              PHOBERT MODEL                       â”‚   â”‚
â”‚  â”‚  (ÄÃ£ Ä‘Æ°á»£c fine-tune cho phÃ¢n tÃ­ch cáº£m xÃºc)      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â†“                               â”‚
â”‚  OUTPUT: POSITIVE (TÃ­ch cá»±c) - Äá»™ tin cáº­y: 95%         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 Ba loáº¡i cáº£m xÃºc

| Sá»‘ thá»© tá»± | NhÃ£n | Tiáº¿ng Viá»‡t | Biá»ƒu tÆ°á»£ng |
|:---------:|:-----|:-----------|:----------:|
| 0 | POSITIVE | TÃ­ch cá»±c | ğŸ˜Š |
| 1 | NEUTRAL | Trung tÃ­nh | ğŸ˜ |
| 2 | NEGATIVE | TiÃªu cá»±c | ğŸ˜Ÿ |

---

## 2. BÆ¯á»šC 1: TIá»€N Xá»¬ LÃ VÄ‚N Báº¢N

### 2.1 Má»¥c Ä‘Ã­ch
LÃ m sáº¡ch vÄƒn báº£n Ä‘á»ƒ mÃ´ hÃ¬nh dá»… hiá»ƒu hÆ¡n.

### 2.2 CÃ¡c bÆ°á»›c xá»­ lÃ½

```
INPUT Gá»C:
"Sáº£n Pháº©m NÃ€Y TUYá»†T Vá»œI!!! ğŸ‘ https://example.com @shop"

                    â†“ BÆ°á»›c 1: Chuyá»ƒn chá»¯ thÆ°á»ng
                    
"sáº£n pháº©m nÃ y tuyá»‡t vá»i!!! ğŸ‘ https://example.com @shop"

                    â†“ BÆ°á»›c 2: XÃ³a URL
                    
"sáº£n pháº©m nÃ y tuyá»‡t vá»i!!! ğŸ‘  @shop"

                    â†“ BÆ°á»›c 3: XÃ³a kÃ½ tá»± Ä‘áº·c biá»‡t
                    
"sáº£n pháº©m nÃ y tuyá»‡t vá»i shop"

                    â†“ BÆ°á»›c 4: XÃ³a khoáº£ng tráº¯ng thá»«a
                    
OUTPUT SAU Xá»¬ LÃ:
"sáº£n pháº©m nÃ y tuyá»‡t vá»i shop"
```

### 2.3 Code thá»±c hiá»‡n

```python
def preprocess_text(self, text):
    # BÆ°á»›c 1: Chuyá»ƒn chá»¯ thÆ°á»ng
    text = text.lower()
    
    # BÆ°á»›c 2: XÃ³a URL
    text = re.sub(r'http\S+|www.\S+', '', text)
    
    # BÆ°á»›c 3: XÃ³a kÃ½ tá»± Ä‘áº·c biá»‡t (giá»¯ tiáº¿ng Viá»‡t)
    text = re.sub(r'[^\w\s...kÃ½ tá»± tiáº¿ng Viá»‡t...]', '', text)
    
    # BÆ°á»›c 4: XÃ³a khoáº£ng tráº¯ng thá»«a
    text = ' '.join(text.split())
    
    return text
```

---

## 3. BÆ¯á»šC 2: TOKENIZATION (TÃCH Tá»ª)

### 3.1 Tokenization lÃ  gÃ¬?
**Tokenization** = QuÃ¡ trÃ¬nh chia vÄƒn báº£n thÃ nh cÃ¡c Ä‘Æ¡n vá»‹ nhá» gá»i lÃ  **tokens**.

### 3.2 BPE (Byte Pair Encoding)

PhoBERT sá»­ dá»¥ng thuáº­t toÃ¡n **BPE** - má»™t phÆ°Æ¡ng phÃ¡p thÃ´ng minh Ä‘á»ƒ tÃ¡ch tá»«:

```
VÃ Dá»¤ 1: Tá»« phá»• biáº¿n
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input:  "tuyá»‡t vá»i"
Output: ["tuyá»‡t", "vá»i"]
         (Má»—i tá»« lÃ  1 token riÃªng vÃ¬ chÃºng phá»• biáº¿n)

VÃ Dá»¤ 2: Tá»« hiáº¿m gáº·p
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input:  "blockbuster"
Output: ["block", "buster"]
         (Tá»« hiáº¿m bá»‹ tÃ¡ch thÃ nh cÃ¡c pháº§n nhá» hÆ¡n)

VÃ Dá»¤ 3: CÃ¢u hoÃ n chá»‰nh
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input:  "sáº£n pháº©m tuyá»‡t vá»i"
Output: ["<s>", "sáº£n", "pháº©m", "tuyá»‡t", "vá»i", "</s>"]
         
         Giáº£i thÃ­ch:
         â€¢ <s>   = Token báº¯t Ä‘áº§u cÃ¢u (Start)
         â€¢ </s>  = Token káº¿t thÃºc cÃ¢u (End)
```

### 3.3 Chuyá»ƒn Token thÃ nh sá»‘ (Token IDs)

Má»—i token Ä‘Æ°á»£c gÃ¡n má»™t sá»‘ ID duy nháº¥t:

```
Tokens:    ["<s>",  "sáº£n",   "pháº©m",  "tuyá»‡t", "vá»i",  "</s>"]
              â†“      â†“        â†“        â†“       â†“       â†“
Token IDs: [  0,    1257,    3456,    5678,   9012,     2  ]
```

### 3.4 Ã nghÄ©a
- **MÃ´ hÃ¬nh khÃ´ng hiá»ƒu chá»¯**, chá»‰ hiá»ƒu **sá»‘**
- Báº£ng tá»« Ä‘iá»ƒn (vocab) chá»©a ~64,000 tokens
- Token ID 0 = `<s>`, Token ID 2 = `</s>`

---

## 4. BÆ¯á»šC 3: EMBEDDING (NHÃšNG Tá»ª)

### 4.1 Embedding lÃ  gÃ¬?

**Embedding** = Chuyá»ƒn Ä‘á»•i má»—i token (sá»‘) thÃ nh má»™t **vector** (danh sÃ¡ch cÃ¡c sá»‘).

```
Táº¡i sao cáº§n Embedding?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Token ID chá»‰ lÃ  sá»‘ Ä‘Æ¡n láº», khÃ´ng chá»©a nghÄ©a
â€¢ Vector embedding chá»©a thÃ´ng tin ngá»¯ nghÄ©a
â€¢ Vector cÃ³ 768 chiá»u (768 sá»‘ thá»±c)
```

### 4.2 Ba loáº¡i Embedding

```
CÃ”NG THá»¨C EMBEDDING:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
E = E_token + E_position + E_segment

Trong Ä‘Ã³:
â€¢ E         = Vector embedding cuá»‘i cÃ¹ng (768 sá»‘)
â€¢ E_token   = Vector nghÄ©a cá»§a tá»«
â€¢ E_position = Vector vá»‹ trÃ­ cá»§a tá»« trong cÃ¢u
â€¢ E_segment = Vector phÃ¢n biá»‡t cÃ¢u (thÆ°á»ng = 0)
```

### 4.3 Giáº£i thÃ­ch chi tiáº¿t tá»«ng loáº¡i

**ğŸ“Œ Token Embedding (E_token):**
```
Má»—i tá»« cÃ³ má»™t vector 768 chiá»u riÃªng, lÆ°u trong báº£ng tra cá»©u.

VÃ­ dá»¥:
â€¢ "sáº£n"   â†’ [0.12, -0.34, 0.56, ..., 0.78]  (768 sá»‘)
â€¢ "pháº©m"  â†’ [0.21, 0.45, -0.12, ..., 0.33]  (768 sá»‘)
â€¢ "tá»‘t"   â†’ [0.89, 0.23, 0.67, ..., 0.11]  (768 sá»‘)

CÃ¡c tá»« cÃ³ nghÄ©a tÆ°Æ¡ng tá»± sáº½ cÃ³ vector gáº§n nhau:
â€¢ "tá»‘t" vÃ  "tuyá»‡t" cÃ³ vector gáº§n nhau
â€¢ "tá»‘t" vÃ  "xáº¥u" cÃ³ vector xa nhau
```

**ğŸ“Œ Position Embedding (E_position):**
```
Cho mÃ´ hÃ¬nh biáº¿t vá»‹ trÃ­ cá»§a tá»« trong cÃ¢u.

CÃ¢u: "Sáº£n pháº©m ráº¥t tá»‘t"
       â†“    â†“   â†“   â†“
Vá»‹ trÃ­: 1    2   3   4

Má»—i vá»‹ trÃ­ cÃ³ 1 vector riÃªng:
â€¢ Vá»‹ trÃ­ 1 â†’ [0.01, 0.02, -0.03, ...]
â€¢ Vá»‹ trÃ­ 2 â†’ [0.05, -0.01, 0.04, ...]
â€¢ ...

Táº¡i sao cáº§n vá»‹ trÃ­?
â€¢ "TÃ´i khÃ´ng thÃ­ch nÃ³" â‰  "NÃ³ khÃ´ng thÃ­ch tÃ´i"
â€¢ Thá»© tá»± tá»« thay Ä‘á»•i nghÄ©a cá»§a cÃ¢u
```

**ğŸ“Œ Segment Embedding (E_segment):**
```
DÃ¹ng Ä‘á»ƒ phÃ¢n biá»‡t cÃ¢u A vÃ  cÃ¢u B (trong bÃ i toÃ¡n so sÃ¡nh 2 cÃ¢u).

Trong phÃ¢n tÃ­ch cáº£m xÃºc (chá»‰ 1 cÃ¢u):
â€¢ Táº¥t cáº£ token Ä‘á»u cÃ³ segment = 0
â€¢ E_segment thÆ°á»ng lÃ  vector toÃ n 0
```

### 4.4 VÃ­ dá»¥ tÃ­nh Embedding

```
CÃ¢u: "sáº£n pháº©m tá»‘t" (3 tá»« + 2 token Ä‘áº·c biá»‡t = 5 tokens)

Token "sáº£n" á»Ÿ vá»‹ trÃ­ 1:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
E_token["sáº£n"]    = [0.12, -0.34, 0.56, ...]
E_position[1]     = [0.01,  0.02, 0.03, ...]
E_segment[0]      = [0.00,  0.00, 0.00, ...]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
E["sáº£n"]          = [0.13, -0.32, 0.59, ...]

Káº¿t quáº£: Ma tráº­n Embedding kÃ­ch thÆ°á»›c (5 x 768)
â€¢ 5 tokens, má»—i token lÃ  1 vector 768 chiá»u
```

---

## 5. BÆ¯á»šC 4: TRANSFORMER LAYERS

### 5.1 Tá»•ng quan

PhoBERT cÃ³ **12 lá»›p Transformer**, má»—i lá»›p gá»“m 2 pháº§n:
1. **Self-Attention**: Há»c má»‘i quan há»‡ giá»¯a cÃ¡c tá»«
2. **Feed-Forward Network**: Xá»­ lÃ½ thÃ´ng tin

```
Input Embedding
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TRANSFORMER LAYER 1   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Self-Attention   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚            â†“            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Feed-Forward NN  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   TRANSFORMER LAYER 2   â”‚
â”‚        ... ...          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
        (láº·p láº¡i 12 láº§n)
             â†“
      Output Vectors
```

---

### 5.2 SELF-ATTENTION (Chi tiáº¿t)

#### 5.2.1 Ã tÆ°á»Ÿng chÃ­nh

Self-Attention giÃºp mÃ´ hÃ¬nh hiá»ƒu **má»‘i quan há»‡ giá»¯a cÃ¡c tá»« trong cÃ¢u**.

```
VÃ Dá»¤:
â”€â”€â”€â”€â”€â”€
CÃ¢u: "Sáº£n pháº©m nÃ y khÃ´ng tá»‘t"

Khi xá»­ lÃ½ tá»« "tá»‘t", mÃ´ hÃ¬nh cáº§n biáº¿t:
â€¢ "khÃ´ng" Ä‘á»©ng trÆ°á»›c "tá»‘t" â†’ nghÄ©a Ä‘áº£o ngÆ°á»£c
â€¢ "tá»‘t" liÃªn quan Ä‘áº¿n "sáº£n pháº©m" (khÃ´ng pháº£i ngáº«u nhiÃªn)

Self-Attention cho phÃ©p má»—i tá»« "nhÃ¬n" vÃ o Táº¤T Cáº¢ cÃ¡c tá»« khÃ¡c.
```

#### 5.2.2 Ba vector: Query, Key, Value

Má»—i tá»« táº¡o ra 3 vector:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  QUERY (Q) - "CÃ¢u há»i"                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚  â€¢ Äáº¡i diá»‡n cho tá»« HIá»†N Táº I Ä‘ang Ä‘Æ°á»£c xá»­ lÃ½            â”‚
â”‚  â€¢ Há»i: "TÃ´i cáº§n chÃº Ã½ Ä‘áº¿n tá»« nÃ o?"                    â”‚
â”‚                                                        â”‚
â”‚  KEY (K) - "ChÃ¬a khÃ³a"                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚  â€¢ Äáº¡i diá»‡n cho Táº¤T Cáº¢ cÃ¡c tá»« trong cÃ¢u                â”‚
â”‚  â€¢ Tráº£ lá»i: "TÃ´i cÃ³ thÃ´ng tin gÃ¬ cÃ³ thá»ƒ há»¯u Ã­ch?"      â”‚
â”‚                                                        â”‚
â”‚  VALUE (V) - "GiÃ¡ trá»‹"                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚  â€¢ Chá»©a thÃ´ng tin THá»°C Sá»° cá»§a má»—i tá»«                   â”‚
â”‚  â€¢ ÄÃ¢y lÃ  thÃ´ng tin sáº½ Ä‘Æ°á»£c truyá»n Ä‘i                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 5.2.3 CÃ¡ch tÃ­nh Q, K, V

```
CÃ”NG THá»¨C:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Q = X Ã— W_Q    (Ma tráº­n Ä‘áº§u vÃ o Ã— Ma tráº­n trá»ng sá»‘ Query)
K = X Ã— W_K    (Ma tráº­n Ä‘áº§u vÃ o Ã— Ma tráº­n trá»ng sá»‘ Key)
V = X Ã— W_V    (Ma tráº­n Ä‘áº§u vÃ o Ã— Ma tráº­n trá»ng sá»‘ Value)

Trong Ä‘Ã³:
â€¢ X    = Ma tráº­n embedding Ä‘áº§u vÃ o, kÃ­ch thÆ°á»›c (n Ã— 768)
         n = sá»‘ token trong cÃ¢u
â€¢ W_Q  = Ma tráº­n trá»ng sá»‘ Query, kÃ­ch thÆ°á»›c (768 Ã— 64)
â€¢ W_K  = Ma tráº­n trá»ng sá»‘ Key, kÃ­ch thÆ°á»›c (768 Ã— 64)
â€¢ W_V  = Ma tráº­n trá»ng sá»‘ Value, kÃ­ch thÆ°á»›c (768 Ã— 64)

Káº¿t quáº£:
â€¢ Q, K, V Ä‘á»u cÃ³ kÃ­ch thÆ°á»›c (n Ã— 64)
```

#### 5.2.4 TÃ­nh Ä‘iá»ƒm Attention

```
BÆ¯á»šC 1: TÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Äiá»ƒm = Q Ã— K^T

Ã nghÄ©a: NhÃ¢n Query cá»§a tá»« hiá»‡n táº¡i vá»›i Key cá»§a táº¥t cáº£ tá»« khÃ¡c
         Ä‘á»ƒ xem tá»« nÃ o "khá»›p" nháº¥t.

Káº¿t quáº£: Ma tráº­n (n Ã— n) - Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng giá»¯a má»i cáº·p tá»«


BÆ¯á»šC 2: Chia tá»· lá»‡ (Scaling)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Äiá»ƒm_scaled = Äiá»ƒm Ã· cÄƒn(64)
            = Äiá»ƒm Ã· 8

Táº¡i sao chia cho cÄƒn(d_k)?
â€¢ d_k = 64 (sá»‘ chiá»u cá»§a Key)
â€¢ Náº¿u khÃ´ng chia, Ä‘iá»ƒm quÃ¡ lá»›n â†’ gradient khÃ´ng á»•n Ä‘á»‹nh
â€¢ Chia Ä‘á»ƒ giá»¯ Ä‘iá»ƒm trong khoáº£ng há»£p lÃ½


BÆ¯á»šC 3: Softmax (Chuáº©n hÃ³a thÃ nh xÃ¡c suáº¥t)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Trá»ng_sá»‘ = softmax(Äiá»ƒm_scaled)

VÃ­ dá»¥:
â€¢ Äiá»ƒm_scaled = [2.5, 0.3, -1.2]
â€¢ Sau softmax  = [0.88, 0.10, 0.02]

Ã nghÄ©a: Tá»•ng cÃ¡c trá»ng sá»‘ = 1 (100%)


BÆ¯á»šC 4: NhÃ¢n vá»›i Value
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Output = Trá»ng_sá»‘ Ã— V

Ã nghÄ©a: Láº¥y tá»•ng cÃ³ trá»ng sá»‘ cá»§a cÃ¡c Value
         Tá»« nÃ o cÃ³ trá»ng sá»‘ cao â†’ Ä‘Ã³ng gÃ³p nhiá»u hÆ¡n
```

#### 5.2.5 CÃ´ng thá»©c tá»•ng há»£p

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                            â•‘
â•‘   Attention(Q, K, V) = softmax( (Q Ã— K^T) Ã· cÄƒn(d_k) ) Ã— V â•‘
â•‘                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Diá»…n giáº£i báº±ng lá»i:
1. NhÃ¢n Query vá»›i Key chuyá»ƒn vá»‹ Ä‘á»ƒ tÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng
2. Chia cho cÄƒn cá»§a 64 Ä‘á»ƒ á»•n Ä‘á»‹nh
3. Ãp dá»¥ng softmax Ä‘á»ƒ cÃ³ xÃ¡c suáº¥t
4. NhÃ¢n vá»›i Value Ä‘á»ƒ láº¥y thÃ´ng tin
```

#### 5.2.6 VÃ­ dá»¥ trá»±c quan

```
CÃ¢u: "Sáº£n pháº©m ráº¥t tá»‘t"
      [0]   [1]  [2] [3]

Ma tráº­n Attention sau softmax:

              Sáº£n    pháº©m   ráº¥t    tá»‘t
           â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
Sáº£n        â”‚ 0.40 â”‚ 0.30 â”‚ 0.15 â”‚ 0.15 â”‚  â†’ Sáº£n chÃº Ã½ Ä‘áº¿n pháº©m
           â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
pháº©m       â”‚ 0.35 â”‚ 0.40 â”‚ 0.10 â”‚ 0.15 â”‚  â†’ pháº©m chÃº Ã½ Ä‘áº¿n Sáº£n
           â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
ráº¥t        â”‚ 0.10 â”‚ 0.10 â”‚ 0.30 â”‚ 0.50 â”‚  â†’ ráº¥t chÃº Ã½ Ä‘áº¿n tá»‘t â­
           â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
tá»‘t        â”‚ 0.15 â”‚ 0.20 â”‚ 0.45 â”‚ 0.20 â”‚  â†’ tá»‘t chÃº Ã½ Ä‘áº¿n ráº¥t â­
           â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜

Nháº­n xÃ©t:
â€¢ "ráº¥t" vÃ  "tá»‘t" cÃ³ attention cao vá»›i nhau (0.50 vÃ  0.45)
â€¢ Äiá»u nÃ y há»£p lÃ½ vÃ¬ "ráº¥t" bá»• nghÄ©a cho "tá»‘t"
â€¢ "Sáº£n" vÃ  "pháº©m" cÅ©ng cÃ³ attention cao vá»›i nhau (0.30 vÃ  0.35)
```

---

### 5.3 MULTI-HEAD ATTENTION

#### 5.3.1 Táº¡i sao cáº§n nhiá»u Head?

```
Má»—i "Head" há»c má»™t loáº¡i quan há»‡ khÃ¡c nhau:

Head 1: Quan há»‡ chá»§ ngá»¯ - Ä‘á»™ng tá»«
        "TÃ´i" â†â†’ "thÃ­ch"

Head 2: Quan há»‡ tÃ­nh tá»« - danh tá»«
        "tá»‘t" â†â†’ "sáº£n pháº©m"

Head 3: Quan há»‡ phá»§ Ä‘á»‹nh
        "khÃ´ng" â†â†’ "tá»‘t"

Head 4: Quan há»‡ Ä‘áº¡i tá»«
        "nÃ³" â†â†’ "sáº£n pháº©m"

... (PhoBERT cÃ³ 12 heads)
```

#### 5.3.2 CÃ¡ch hoáº¡t Ä‘á»™ng

```
CÃ”NG THá»¨C:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MultiHead = Concat(head_1, head_2, ..., head_12) Ã— W_O

Trong Ä‘Ã³:
â€¢ head_i  = Káº¿t quáº£ attention cá»§a head thá»© i (kÃ­ch thÆ°á»›c n Ã— 64)
â€¢ Concat  = GhÃ©p 12 heads láº¡i thÃ nh (n Ã— 768)
â€¢ W_O     = Ma tráº­n output, kÃ­ch thÆ°á»›c (768 Ã— 768)

QuÃ¡ trÃ¬nh:
1. Cháº¡y 12 attention heads song song
2. Má»—i head cho output (n Ã— 64)
3. GhÃ©p 12 outputs: (n Ã— 64) Ã— 12 = (n Ã— 768)
4. NhÃ¢n vá»›i W_O Ä‘á»ƒ káº¿t há»£p thÃ´ng tin
```

---

### 5.4 FEED-FORWARD NETWORK

#### 5.4.1 Cáº¥u trÃºc

```
Sau Self-Attention, má»—i vector Ä‘i qua má»™t máº¡ng neural Ä‘Æ¡n giáº£n:

Input (768 chiá»u)
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Fully Connected 1   â”‚
â”‚ 768 â†’ 3072 chiá»u    â”‚
â”‚ (Má»Ÿ rá»™ng lÃªn 4 láº§n) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    GELU Activation  â”‚
â”‚ (HÃ m kÃ­ch hoáº¡t)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Fully Connected 2   â”‚
â”‚ 3072 â†’ 768 chiá»u    â”‚
â”‚ (Thu nhá» vá» ban Ä‘áº§u)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
Output (768 chiá»u)
```

#### 5.4.2 CÃ´ng thá»©c

```
CÃ”NG THá»¨C FFN:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FFN(x) = GELU(x Ã— W1 + b1) Ã— W2 + b2

Trong Ä‘Ã³:
â€¢ x   = Vector Ä‘áº§u vÃ o (768 chiá»u)
â€¢ W1  = Ma tráº­n trá»ng sá»‘ 1, kÃ­ch thÆ°á»›c (768 Ã— 3072)
â€¢ b1  = Bias 1 (3072 chiá»u)
â€¢ W2  = Ma tráº­n trá»ng sá»‘ 2, kÃ­ch thÆ°á»›c (3072 Ã— 768)
â€¢ b2  = Bias 2 (768 chiá»u)
â€¢ GELU = HÃ m kÃ­ch hoáº¡t (Gaussian Error Linear Unit)
```

#### 5.4.3 HÃ m GELU

```
GELU lÃ  gÃ¬?
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Má»™t loáº¡i hÃ m kÃ­ch hoáº¡t (giá»‘ng ReLU nhÆ°ng mÆ°á»£t hÆ¡n)
â€¢ GiÃºp mÃ´ hÃ¬nh há»c cÃ¡c quan há»‡ phi tuyáº¿n

CÃ”NG THá»¨C GELU (xáº¥p xá»‰):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GELU(x) â‰ˆ 0.5 Ã— x Ã— (1 + tanh(0.7978 Ã— (x + 0.0356 Ã— xÂ³)))

Äá»“ thá»‹ (so sÃ¡nh vá»›i ReLU):

     â”‚
  2  â”¤          â•±  â† GELU (Ä‘Æ°á»ng cong mÆ°á»£t)
     â”‚        â•±
  1  â”¤      â•±
     â”‚    â•±
  0  â”¼â”€â”€â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€
     â”‚â•±        
 -1  â”¤
     â””â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€â”¬â”€â”€
       -2 -1  0  1  2
```

---

### 5.5 RESIDUAL CONNECTION + LAYER NORMALIZATION

#### 5.5.1 Residual Connection (Káº¿t ná»‘i táº¯t)

```
Ã tÆ°á»Ÿng: Cá»™ng input ban Ä‘áº§u vÃ o output

Táº¡i sao?
â€¢ GiÃºp gradient cháº£y dá»… dÃ ng qua nhiá»u lá»›p
â€¢ TrÃ¡nh hiá»‡n tÆ°á»£ng "vanishing gradient"
â€¢ MÃ´ hÃ¬nh cÃ³ thá»ƒ há»c "khÃ´ng lÃ m gÃ¬" náº¿u cáº§n

CÃ”NG THá»¨C:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Output = Input + Sublayer(Input)

VÃ­ dá»¥:
â€¢ x = [0.5, 0.3, 0.2, ...]          (Input)
â€¢ Attention(x) = [0.1, -0.1, 0.2, ...] (Output tá»« Attention)
â€¢ Káº¿t quáº£ = [0.6, 0.2, 0.4, ...]    (Cá»™ng láº¡i)
```

#### 5.5.2 Layer Normalization

```
Má»¥c Ä‘Ã­ch: Chuáº©n hÃ³a Ä‘á»ƒ training á»•n Ä‘á»‹nh

CÃ”NG THá»¨C:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LayerNorm(x) = gamma Ã— (x - trung_bÃ¬nh) Ã· cÄƒn(phÆ°Æ¡ng_sai + epsilon) + beta

Trong Ä‘Ã³:
â€¢ x            = Vector Ä‘áº§u vÃ o (768 chiá»u)
â€¢ trung_bÃ¬nh   = GiÃ¡ trá»‹ trung bÃ¬nh cá»§a 768 pháº§n tá»­
â€¢ phÆ°Æ¡ng_sai   = PhÆ°Æ¡ng sai cá»§a 768 pháº§n tá»­
â€¢ epsilon      = Sá»‘ ráº¥t nhá» (0.000001) Ä‘á»ƒ trÃ¡nh chia cho 0
â€¢ gamma, beta  = Tham sá»‘ há»c Ä‘Æ°á»£c

VÃ­ dá»¥:
â€¢ Input: [2, 4, 6, 8]
â€¢ Trung bÃ¬nh = 5
â€¢ PhÆ°Æ¡ng sai = 5
â€¢ Output = gamma Ã— [(2-5)/2.24, (4-5)/2.24, ...] + beta
         = gamma Ã— [-1.34, -0.45, 0.45, 1.34] + beta
```

---

## 6. BÆ¯á»šC 5: CLASSIFICATION (PHÃ‚N LOáº I)

### 6.1 Láº¥y vector Ä‘áº¡i diá»‡n cho cÃ¢u

```
Sau khi Ä‘i qua 12 Transformer layers:

Tokens: [<s>, "sáº£n", "pháº©m", "tá»‘t", </s>]
Vectors: [h0,   h1,    h2,    h3,   h4]
          â†‘
          â”‚
          â””â”€â”€ h0 (vector cá»§a <s>) Ä‘Æ°á»£c dÃ¹ng lÃ m Ä‘áº¡i diá»‡n cho Cáº¢ CÃ‚U

Táº¡i sao dÃ¹ng token <s>?
â€¢ Vá»‹ trÃ­ Ä‘áº§u tiÃªn, "nhÃ¬n tháº¥y" toÃ n bá»™ cÃ¢u qua attention
â€¢ Chá»©a thÃ´ng tin tá»•ng há»£p cá»§a cÃ¢u
```

### 6.2 Lá»›p phÃ¢n loáº¡i (Classification Layer)

```
CÃ”NG THá»¨C:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logits = h0 Ã— W_c + b_c

Trong Ä‘Ã³:
â€¢ h0    = Vector CLS (768 chiá»u) - Ä‘áº¡i diá»‡n cÃ¢u
â€¢ W_c   = Ma tráº­n phÃ¢n loáº¡i (768 Ã— 3)
â€¢ b_c   = Bias (3 chiá»u)
â€¢ logits = Äiá»ƒm thÃ´ cho 3 lá»›p (3 chiá»u)

VÃ­ dá»¥:
â€¢ h0 = [0.5, 0.3, -0.2, ..., 0.1]  (768 sá»‘)
â€¢ W_c = ma tráº­n (768 Ã— 3)
â€¢ logits = [2.5, 0.3, -1.2]
           â†‘    â†‘     â†‘
         POS  NEU   NEG
```

---

## 7. BÆ¯á»šC 6: SOFTMAX VÃ€ Káº¾T QUáº¢

### 7.1 HÃ m Softmax

```
Chuyá»ƒn logits (Ä‘iá»ƒm thÃ´) thÃ nh xÃ¡c suáº¥t (tá»•ng = 100%)

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                            â•‘
â•‘           P(lá»›p_k) = e^(z_k) Ã· tá»•ng(e^(z_j))              â•‘
â•‘                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Giáº£i thÃ­ch:
â€¢ z_k = logit cá»§a lá»›p k
â€¢ e   = sá»‘ Euler â‰ˆ 2.718
â€¢ e^x = hÃ m mÅ© (luÃ´n dÆ°Æ¡ng)
â€¢ Chia cho tá»•ng Ä‘á»ƒ chuáº©n hÃ³a thÃ nh xÃ¡c suáº¥t
```

### 7.2 VÃ­ dá»¥ tÃ­nh Softmax tá»«ng bÆ°á»›c

```
BÆ¯á»šC 1: CÃ³ logits
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logits = [2.5, 0.3, -1.2]
          â†‘    â†‘     â†‘
         POS  NEU   NEG


BÆ¯á»šC 2: TÃ­nh e mÅ© cho tá»«ng logit
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
e^2.5  = 12.18  (positive)
e^0.3  = 1.35   (neutral)
e^-1.2 = 0.30   (negative)


BÆ¯á»šC 3: TÃ­nh tá»•ng
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Tá»•ng = 12.18 + 1.35 + 0.30 = 13.83


BÆ¯á»šC 4: Chia Ä‘á»ƒ cÃ³ xÃ¡c suáº¥t
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
P(positive) = 12.18 Ã· 13.83 = 0.88 = 88%
P(neutral)  = 1.35 Ã· 13.83  = 0.10 = 10%
P(negative) = 0.30 Ã· 13.83  = 0.02 = 2%

Tá»•ng xÃ¡c suáº¥t = 88% + 10% + 2% = 100% âœ“


BÆ¯á»šC 5: Láº¥y káº¿t quáº£
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NhÃ£n dá»± Ä‘oÃ¡n = lá»›p cÃ³ xÃ¡c suáº¥t cao nháº¥t = POSITIVE
Äá»™ tin cáº­y   = xÃ¡c suáº¥t cá»§a nhÃ£n Ä‘Ã³ = 88%
```

### 7.3 Code thá»±c hiá»‡n

```python
# Sau khi cÃ³ logits tá»« model
logits = outputs.logits  # [2.5, 0.3, -1.2]

# Ãp dá»¥ng softmax
probabilities = torch.softmax(logits, dim=1)[0]
# probabilities = [0.88, 0.10, 0.02]

# Láº¥y nhÃ£n cÃ³ xÃ¡c suáº¥t cao nháº¥t
prediction = torch.argmax(probabilities).item()  # = 0 (positive)

# Láº¥y Ä‘á»™ tin cáº­y
confidence = float(probabilities[prediction])    # = 0.88 (88%)
```

---

## 8. VÃ Dá»¤ THá»°C Táº¾ Tá»ª A-Z

### Input ban Ä‘áº§u:
```
"Sáº£n pháº©m nÃ y TUYá»†T Vá»œI!!! ğŸ‘ğŸ‘ğŸ‘"
```

### BÆ°á»›c 1: Tiá»n xá»­ lÃ½
```
â†’ "sáº£n pháº©m nÃ y tuyá»‡t vá»i"
```

### BÆ°á»›c 2: Tokenization
```
â†’ Tokens: ["<s>", "sáº£n", "pháº©m", "nÃ y", "tuyá»‡t", "vá»i", "</s>"]
â†’ IDs:    [0, 1257, 3456, 789, 5678, 9012, 2]
```

### BÆ°á»›c 3: Embedding
```
â†’ Ma tráº­n (7 Ã— 768)
   Má»—i hÃ ng lÃ  1 vector 768 chiá»u
```

### BÆ°á»›c 4: 12 Transformer Layers
```
â†’ Ma tráº­n (7 Ã— 768) Ä‘Ã£ Ä‘Æ°á»£c "tinh chá»‰nh"
   CÃ¡c tá»« Ä‘Ã£ "nhÃ¬n tháº¥y" nhau qua attention
```

### BÆ°á»›c 5: Láº¥y vector CLS
```
â†’ h0 = vector Ä‘áº§u tiÃªn, 768 chiá»u
```

### BÆ°á»›c 6: Classification
```
â†’ logits = h0 Ã— W_c + b_c = [3.2, 0.5, -2.1]
```

### BÆ°á»›c 7: Softmax
```
e^3.2 = 24.53
e^0.5 = 1.65
e^-2.1 = 0.12
Tá»•ng = 26.30

P(positive) = 24.53 / 26.30 = 93.3%
P(neutral)  = 1.65 / 26.30  = 6.3%
P(negative) = 0.12 / 26.30  = 0.4%
```

### Káº¿t quáº£ cuá»‘i cÃ¹ng:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Káº¾T QUáº¢ PHÃ‚N TÃCH                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“ BÃ¬nh luáº­n: "Sáº£n pháº©m nÃ y TUYá»†T Vá»œI!!! ğŸ‘ğŸ‘ğŸ‘"       â”‚
â”‚  ğŸ˜Š Cáº£m xÃºc:   POSITIVE (TÃ­ch cá»±c)                      â”‚
â”‚  ğŸ“Š Äá»™ tin cáº­y: 93.3%                                   â”‚
â”‚                                                         â”‚
â”‚  Chi tiáº¿t xÃ¡c suáº¥t:                                     â”‚
â”‚  â”œâ”€â”€ TÃ­ch cá»±c:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 93.3%           â”‚
â”‚  â”œâ”€â”€ Trung tÃ­nh:  â–ˆ 6.3%                                â”‚
â”‚  â””â”€â”€ TiÃªu cá»±c:    â– 0.4%                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ TÃ“M Táº®T CÃC CÃ”NG THá»¨C

| # | TÃªn | CÃ´ng thá»©c | Má»¥c Ä‘Ã­ch |
|:-:|:----|:----------|:---------|
| 1 | Embedding | E = E_token + E_position + E_segment | NhÃºng tá»« vÃ o vector |
| 2 | Query/Key/Value | Q=XW_Q, K=XW_K, V=XW_V | Táº¡o 3 vector cho attention |
| 3 | Attention Score | Score = (Q Ã— K^T) Ã· cÄƒn(d_k) | TÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng |
| 4 | Attention | Att = softmax(Score) Ã— V | Láº¥y thÃ´ng tin cÃ³ trá»ng sá»‘ |
| 5 | Multi-Head | MH = Concat(heads) Ã— W_O | Káº¿t há»£p nhiá»u heads |
| 6 | FFN | FFN = GELU(xW1 + b1)W2 + b2 | Xá»­ lÃ½ phi tuyáº¿n |
| 7 | Layer Norm | LN = gamma Ã— (x-Î¼)/Ïƒ + beta | Chuáº©n hÃ³a |
| 8 | Residual | Out = x + Sublayer(x) | Káº¿t ná»‘i táº¯t |
| 9 | Classification | logits = h_CLS Ã— W_c + b_c | TÃ­nh Ä‘iá»ƒm phÃ¢n loáº¡i |
| 10 | Softmax | P(k) = e^z_k Ã· Î£e^z_j | Chuyá»ƒn thÃ nh xÃ¡c suáº¥t |

---

## ğŸ”— THAM KHáº¢O

- Code chÃ­nh: [sentiment_analyzer.py](file:///d:/LVTN/LVTN2025/sentiment-analysis-system/backend/src/services/sentiment_analyzer.py)
- PhoBERT paper: [PhoBERT: Pre-trained language models for Vietnamese](https://arxiv.org/abs/2003.00744)
- Transformer paper: [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
